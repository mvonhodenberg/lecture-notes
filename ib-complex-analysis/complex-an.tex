\documentclass[egregdoesnotlikesansseriftitles,a4paper]{scrartcl}

\usepackage{martin}

\title{IB Complex Analysis}
\author{Martin von Hodenberg (\texttt{mjv43@cam.ac.uk})}
\date{Last updated: \today}

\allowdisplaybreaks

\begin{document}

\maketitle
These are my notes\footnote{Notes are posted online on \href{https://mjv43.user.srcf.net/}{my website}.} for the IB course Complex Analysis, which was lectured in Lent 2022 at Cambridge by Prof. N.Wickramasekera.
\newpage
\tableofcontents
\newpage

\section{Basic notions}
Recall definitions in $\mathbb{C}$ from IA courses. Note that $d (z,w)=|z-w|$ defines a metric on $\mathbb{C}$ (the standard metric). For $a \in \mathbb{C}$ and $r >0$, we write $D (a,r)= \left\{z \in \mathbb{C}: \ |z-a|<r \right\}$ for the open ball with centre $a$ and radius $r$. 
\begin{definition*}[Open subset of $\mathbb{C}$]
     A subset $U \subset \mathbb{C}$ is open wrt. the standard metric if for all $a \in U$, there exists an $r$ such that $D (a,r) \in U$.
\end{definition*} 
\begin{remark}
     This is equivalent to being open wrt. the Euclidean metric on $\mathbb{R}^{2} $.
\end{remark}

This course is about complex valued functions of a single variable, i.e functions \[
f: A \rightarrow \mathbb{C}, \quad \text{where } A \subset \mathbb{C}
.\] 
Identifying $\mathbb{C}$ with $\mathbb{R}^2$ in the usual way, we can write $f=u+iv$ for real functions $u,v$ and thus define $u= \operatorname{Re} (f)$, $v=\operatorname{Im} (f)$. 
Almost exclusively we'll focus on differentiable functions $f$. But first let's recall continuity. 
\begin{definition*}[Continuous function on $\mathbb{C}$]
     The function $f$ (as above) is continuous at a point $w \in A$ if \[
     \forall \varepsilon >0, \ \exists \delta >0 \text{ such that } \forall z \in A,\quad  |z-w|<\delta \implies |f (z)- f (w)| <\varepsilon
     .\] 
\end{definition*}
\begin{remark}
     This is equivalent to saying that $\lim_{z \rightarrow w} f(z)=f (w) $. 
\end{remark}

\subsection{Complex differentiation}
Let $f: U \rightarrow \mathbb{C}$, where $U$ is open. 
\begin{definition*}[Differentiability]
     $f$ is differentiable at $w \in U$ if the limit \[
     f' (w)=\lim_{z \rightarrow w} \frac{f (z)-f (w)}{z-w}
     .\] exists at a complex number.
\end{definition*}
\begin{definition*}[Holomorphic function]
     $f$ is \vocab{holomorphic}\footnotemark at $w \in U$ if there is $\varepsilon >0$ such that $D (w, \varepsilon)\subset U$ and $f$ is differentiable at every point in $D (w, \varepsilon)$. 

     Equivalently, $f$ is holomorphic in $U$ if $f$ is holomorphic at every point in $U$, or equivalently, $f$ is differentiable at every point in $U$.
\end{definition*}\footnotetext{Sometimes we use "analytic" to mean holomorphic.}
Usual rules of differentiation of real functions of a real variable hold for complex functions. Derivatives of sums, products, quotients of functions are obtained in the same way (can easily be checked). 

\begin{proposition}
     The chain rule for composite functions also holds: if $f: U \rightarrow \mathbb{C}$, $g: V \rightarrow \mathbb{C}$ with $f (U) \subset V$, and $h= g \circ f : U \rightarrow \mathbb{C}$. If $f$ is differentiable at $w \in U$ and $g$ is differentiable at $f (w)$, then $h$ is differentiable at $w$ with \[
     h' (w)=(g \circ f)' (w)= f' (w) (g' \circ f)(w)
     .\] 
\end{proposition}
\begin{proof}
     Omitted; analagous to the proof for the real case.
\end{proof}
We might ask ourselves a question: 

Write $f (z)= u (x,y)+iv (x,y)$, $z=x+iy$. Is differentiability of $f$ at a point $w=c+id \in U$ is the same as differentiability of $u $ and $v$ at $(c,d)$? 

Recall from IB Analysis \& Topology that $u : U \rightarrow \mathbb{R}$ is differentiable at $(c,d) \in U$ if there is a "good linear approximation of $u$ at $(c,d)$". We can show that if  $u$ is differentiable at $c,d$ then $L$ (the derivative of $u$ at $(c,d)$) is uniquely defined, and we write $L=Du (c,d)$; moreover, $L$ is given by the partial derivatives of $u$, i.e \[
L (x,y)= \left(\frac{\partial u}{\partial x} (c,d)\right)x + \left( \frac{\partial u}{\partial y}(c,d)\right)y
.\]  

The answer to the above question is \textbf{no} (otherwise complex analysis would be useless!). Now we want to characterise differentiability of $f$ in terms of $u$ and $v$. 

\begin{theorem}[Cauchy-Riemann equations]
     This theorem states that $f=u+iv: \ U \rightarrow \mathbb{C}$ is differentiable at $w=c+id \in U$ if and only if 

     $u,v$ are differentiable at $(c,d) \in U$ \textbf{and} $u,v$ satisfy the Cauchy-Riemann equations at $(c,d)$: \[
     \frac{\partial u}{\partial x}=\frac{\partial v}{\partial y} \quad \text{and} \quad \frac{\partial u}{\partial y}=- \frac{\partial v}{\partial x}
     .\]  
     If $f$ is differentiable at $w=c+id$, then \[
     f' (w)= \frac{\partial u}{\partial x} (c,d)+i \frac{\partial v}{\partial x} (c,d)
     .\]  There are three other such expressions following from the Cauchy-Riemann equations. 
\end{theorem}
\begin{proof}
     $f$ is differentiable at $w$ with derivative $f' (w)=p+iq$:
     \begin{align*}
         \iff & \lim_{z \rightarrow w} \frac{f (z)- f (w)}{z-w}=p+iq\\
         \iff & \lim_{z \rightarrow w} \frac{f (z)- f (w)- (z-w)(p+iq)}{|z-w|}=0\\
     \end{align*}
     Writing $f=u+iv$ and separating real and imaginary parts, the above holds if and only if 
     \begin{align*}
        & \lim_{(x,y) \rightarrow (c,d)} \frac{u (x,y)- u (c,d)-p (x-c)+q (y-d)}{\sqrt{(x-c)^2+ (y-d)^2}}=0\\
        \text{and } & \lim_{(x,y) \rightarrow (c,d)} \frac{v (x,y)- v (c,d)-q (x-c)+p (y-d)}{\sqrt{(x-c)^2+ (y-d)^2}}=0\\
     \end{align*}
     This is precisely the statement that $u$ is differentiable at $(c,d)$ with $Du (c,d)(x,y)=px-qy$, and $v$ is differentiable at $(c,d)$ with $Dv (c,d)(x,y)=qx+py$. 

     So $\iff$ $u,v$ are differentiable at $(c,d)$ and $u_{x}(c,d)=p=v_{y}(c,d)$, $u_{y}(c,d)=-q=-v_{x}(c,d)$, i.e the Cauchy-Riemann equations hold at $(c,d)$. 

     We also get from the above that if $f$ is differentiable at $w$, then $f' (w)=p+iq=u_{x}(c,d)+iv_{x} (c,d)$.  
\end{proof}
\begin{remark}
     $u,v$ satisfying the Cauchy-Riemann equations at a point does \textbf{not} guarantee differentiability of $f$ on its own. We also can proceed in a more simple way if we simply want to show the reverse implication, by writing \[
     f' (w)=\lim_{z \rightarrow w} \frac{f (z)- f (w)}{z-w}=\lim_{h \rightarrow 0} \frac{f (w+h)-f (w)}{h}
     ,\]
     and then choosing $h = t \in \mathbb{R}$ and $h=it$ (since we can choose any direction we want for $h$) in order to get that $u_{x},u_{y},v_{x},v_{y}$ exist and satisfy the Cauchy-Riemann equations.   
\end{remark}
\begin{example*}[Differentiability (?) of conjugation map]
      Let $f (z)=\overline{z} =x-iy$. For this, $u =x, v=-1$, so $u_{x}=1, v_{y}=-1$ and so the C-R equations are not satisfied and $f$ is not differentiable at any point.  
\end{example*}
\begin{corollary}
     Let $f=u+iv: U \rightarrow \mathbb{C}$. If $u,v$ have continuous partial derivatives at $(c,d) \in U$ and satisfy the C-R equations there, then $f$ is differentiable at $w=c+id$.
     
     In particular, if $u,v$ are $\mathbb{C}^{1}$ functions on $U$ (i.e have continuous partial derivatives in $U$) satisfying the C-R equations in $U$, then $f$ is holomorphic in $U$.
\end{corollary}
\begin{proof}
      Continuity of partial derivatives of $u$ implies that $u$ is differentiable, and similarly for $v$ (IB Analysis \& Topology). So the corollary follows from the C-R theorem.
\end{proof}
Complex differentiability is much more restrictive than real differentiability of real and imaginary parts (because of the additional requirement that the Cauchy-Riemann equations must hold). This leads to surprising theorems compared to the real case, for example 
\begin{itemize}
     \item[(a)] If $f: \mathbb{C} \rightarrow \mathbb{C}$ is holomorphic and bounded, then $f$ is constant! (Liouville's theorem). This is false for real functions; for example $\sin (x): \mathbb{R} \rightarrow \mathbb{R}$ . 
     \item[(b)] If $f: U \rightarrow \mathbb{C}$ is holomorphic, then $f$ is infinitely differentiable on $U$.  
\end{itemize}
We will prove these later on. Note that (b) implies that partial derivatives of $u,v$ of all orders exists. So we can differentiate the Cauchy-Riemann equations to get: 
\begin{align*}
     &(u_{x})_x=(v_{y})_x \implies u_{xx}=v_{yx} \text{  and} \\
     &(u_{y})_y=(-v_{x})_y \implies u_{yy}=-v_{xy}.
\end{align*} 
This gives $\nabla^2 u=u_{xx}+u_{yy}=0$ in $U$. Similarly $\nabla^2 v=0$ in $U$.

This means that real and imaginary parts of a holomorphic function are harmonic. This gives a deep connection between harmonic functions and complex analysis; some theorems can be viewed as giving results about harmonic functions. 

Now we need some definitions before the next corollary.
\begin{definition*}
      \begin{enumerate}
           \item A curve is a continuous map $\gamma: [a,b] \rightarrow \mathbb{C}$, where $[a,b] \subset \mathbb{R}$ is a closed interval. We say $\gamma$ is a $C^{1}$ curve if $\gamma'$ exists and is continuous on $[a,b]$. 
           \item An open set $U \subset \mathbb{C}$ is path-connected if for any two points $z,w \in U$, there is a curve $\gamma: [0,1] \rightarrow U$ such that $\gamma (0)=z$ and $\gamma (1)=w$. 
           \item A domain is a non-empty, open, path-connected subset of $\mathbb{C}$.  
      \end{enumerate}
\end{definition*}
\begin{corollary}
     If $U \in C$ is a domain and $f: U \rightarrow \mathbb{C}$ is holomorphic with $f' (z)=0$ for every $z \in U$, then $f$ is constant.
\end{corollary}
\begin{proof}
      Write $f=u+iv$. By the C-R equations, $f'=0 \implies Du=Dv=0$ in $U$. Since $U$ is a domain, this means (IA Analysis and Topology) that $u$ and $v$ are constant, i.e $f$ is constant.
\end{proof}
Now we want to look at some examples of holomorphic functions other than polynomials on $\mathbb{C}$ and rational functions on their domains. We now look at power series, which will give us a wealth of examples. 

\subsection{Power series}\label{powerseriessection}
Recall the next theorem from IA Analysis:
\begin{definition*}[Radius of convergence]
      If $(c_{n})_{n=0}^{ \infty}$ is a sequence of complex numbers, then there is a unique number $R \in [0, \infty]$ such that the power series \[
      \sum_{n=0}^{ \infty}c_{n}(z-a)^{n} \qquad z,a \in \mathbb{C}
      .\] 
      converges absolutely if $|z-a|<R$ and diverges if $|z-a|>R$. If $0<r<R$, then the series converges uniformly wrt $z$ on the compact disk $D_{r}=\left\{z \in \mathbb{C}: \ |z-a|<R\right\}$. 

      We call $R$ the radius of convergence of the power series. Note that when $z=R$, we cannot say anything in general about convergence.
\end{definition*}
\begin{theorem}
      Let $\sum_{n=0}^{ \infty}c_{n}(z-a)^{n}$ be a power series with radius of convergence $R>0$. Fix $a \in \mathbb{C}$, and define $f: D (a,R)\rightarrow \mathbb{C}$ by $f (z)= \sum_{n=0}^{ \infty}c_{n}(z-a)^{n}$. Then
      \begin{enumerate}
           \item $f$ is holomorphic on $D (a,R)$. 
           \item The derived series $\sum_{n=1}^{ \infty}nc_{n}(z-a)^{n-1}$ also has radius of convergence $R$, and \[
           f' (z)=\sum_{n=1}^{ \infty}nc_{n}(z-a)^{n-1} \quad \forall z \in D (a,R)
           .\] 
           \item $f$ has derivatives of all orders on $D (a,R)$, and $c_{n}= \frac{f^{(n)}(a)}{n!}$. 
           \item If $f$ vanishes on $D (a, \varepsilon)$ for some $\varepsilon>0$, then $f \equiv 0$ on $D (a,R)$. 
      \end{enumerate}
\end{theorem}
\begin{proof}
      \textbf{Parts (i) and (ii)}: By considering $g (z)=f (z+a)$, we assume WLOG that $a=0$. So $f (z)=\sum_{n=0}^{ \infty}c_{n}z^{n}$ for $z \in D (0,R)$. 

     The derived series $\sum_{n=1}^{ \infty}nc_{n}z^{n-1}$ will have some radius of convergence $R_1 \in [0, \infty]$. Now let $z \in D (0,R)$ be arbitrary. Choose $\rho$ such that $|z|<\rho<R$. Then since $n |\frac{z}{\rho}|^{n-1} \rightarrow 0 $ as $n \rightarrow \infty$, we have \[
     n |c_n||z|^{n-1}=n |c_n||\frac{z}{\rho}|^{n-1}\rho^{n-1} \leq |c_n|p^{n-1}
     .\]  
     for sufficiently large $n$. Since $\sum_{}^{}|c_{n}|\rho^{n}$ converges, it follows that $\sum_{n=1}^{ \infty}nc_{n}z^{n-1}$ converges. Thus $D (0,R)\subset D (0,R_1 )$, i.e $R_1 \geq R$. Since \[
     |c_{n}||z|^{n} \leq n|c_{n}||z|^{n}=|z|\left(|c_{n}||z|^{n-1}\right)
     ,\] 
     if $\sum_{}^{}n |c_{n}||z|^{n-1}$ converges then so does $\sum_{}^{}|c_{n}||z|^{n}$, so $R_1 \leq R$. So $R_1 =R$. 
     
     To prove that $f$ is differentiable with $f' (z)=\sum_{n=1}^{ \infty}nc_{n}(z-a)^{n-1}$, fix $z \in D (0,R)$. The key idea is that this is equivalent to continuity at $z$ of the function 
     \begin{equation*}
          g: D (0,R) \rightarrow \mathbb{C}, \quad g (w)=
           \begin{cases}
                \frac{f (w)- f (z)}{w-z} & w \neq z\\
                \sum_{n=1}^{ \infty}nc_{n}z^{n-1} & w=z.
           \end{cases}          
     \end{equation*}
     By subbing in $f$ we can write $g (w)=\sum_{n=1}^{ \infty}h_{n}(w)$ where 
     \begin{equation*}
          h_{n} (w)=
          \begin{cases}
               \frac{c_{n}(w^{n}-z^{n})}{w-z} & w \neq z\\
               nc_{n}z^{n-1} & w=z.
          \end{cases}  
     \end{equation*}
     Now $h_{n}$ is continuous on $D (0,R)$ (since $w \rightarrow w^{n}$ is differentiable with derivative $nw^{n-1}$). Using $ \frac{w^{n}-z^{n}}{w-z}=\sum_{j=0}^{n-1}z^{j}w^{n-1-j}$, we get that for any $r$ with $|z|<r<R$ and any $w \in D (0,r), |h_{n}(w)|\leq n |c_{n}|r^{n-1} \equiv M_{n}$. Since $\sum M_{n} < \infty$, by the Weierstrass M-test that $\sum_{}^{}h_{n}$ converges uniformly on $D (0,r)$. But a uniform limit of continuous functions is continuous, so $g = \sum_{}^{}h_{n}$ is continuous in $D (0,r)$ and in particular at $z$.

     \textbf{Part (iii)}: Repeatedly apply (ii). The formula $c_{n}= \frac{f^{(n)(a)}}{n!}$ follows by differentiating the series $n$ times and setting $z=a$. 
     
     \textbf{Part (iv)}: If $f=0$ in $D (a, \varepsilon)$, then $f^{(n)}(a)=0$ for all $n$, so $c_{n}=0$ for all $n$ and hence $f=0$ in $D (a,R)$. 
\end{proof}
If $f: \mathbb{C} \rightarrow \mathbb{C}$ is holomorphic on all of $\mathbb{C}$, we say $f$ is entire. 

\begin{proposition}\label{eprop}
      The complex exponential function is defined by \[
      e^{z}= \operatorname{exp}(z)= \sum_{n=0}^{ \infty} \frac{z^{n}}{n!}
      .\] 
      \begin{itemize}
           \item[(i)] $e^{z}$ is entire, with $(e^{z})'=e^{z}$. 
           \item[(ii)] $e^{z} \neq 0$ and $e^{z+w}=e^{z}e^{w}$ for all $z,w \in \mathbb{C}$.
           \item[(iii)] $e^{x+iy}=e^{x}(\cos (y)+i sin (y))$ for $x,y \in \mathbb{R}$. 
           \item[(iv)] $e^{z}=1$ iff $z=2n \pi i$ for some $n \in \mathbb{Z}$. 
           \item[(v)] Let $z \in \mathbb{C}$. There exists $w \in \mathbb{C}$ such that $e^{w}=z$ iff $z \neq 0$.  
      \end{itemize}
\end{proposition}
\begin{proof}
     \textbf{Part (i):} The r.o.c of the series is $ \infty$. To see $(e^{z}=z'),$ differentiate the series term by term using the previous theorem. 

     \textbf{Part (ii):} Fix any $w \in \mathbb{C}$ and set $F (z)= e^{z+w}e^{-z}$. Then $F' (z)=-e^{z+w}e^{-z}+e^{z+w}e^{-z}=0$, so $F(z)$ is a constant. Thus $F (z)=F (0)=e^{w}$ for all $z \in \mathbb{C}$. Thus \[
     e^{z+w}e^{-z}=e^{w} \quad \forall z,w \in \mathbb{C}
     .\] Taking $w=0$, $e^{z}e^{-z}=1$. So $e^{z} \neq 0$. Multiplying by $e^{z}$, we get $e^{z+w}=e^{z}e^{w}$. 

     \textbf{Part (iii):} $e^{x+iy}=e^{x}e^{iy}$ by (ii). Now use the definition of $e^{iy}$, and the series for $\sin (y), \cos (y)$ for $y \in \mathbb{R}$.

     \textbf{Part (iv) and (v):} Follow from (iii). (Exercise)
\end{proof}
\begin{definition*}[Logarithm]
      Given $z \in \mathbb{C}$, we say a complex $w \in \mathbb{C}$ is a \vocab{logarithm} of $z$ if $e^{w}=z$. 

      By Proposition \ref{eprop}(v), $z$ has a logarithm iff $z \neq 0$. By (ii) and (iv), if $z \neq 0$ then $z$ has infinitely many logarithms, with any two differing from each other by $2n \pi i$ for some integer $n$. 
      
      If $w$ is a logarithm of $z$, then $e^{\operatorname{Re}(w)}=|z|$, so $\operatorname{Re}(w)=\operatorname{log} |z|$ (the real logarithm of the positive number $|z|$); in particular, this is well-defined.
\end{definition*}
\begin{definition*}[Branch of a logarithm]
      Let $U \subset \mathbb{C} \backslash \left\{0\right\}$ be open. Then a branch of logarithm on $U$ is a continuous function $\lambda: U \rightarrow \mathbb{C}$ such that $e^{\lambda (z)}=z$ for each $z \in U$.
\end{definition*}
\begin{proposition}
      If $\lambda$ is a branch of log on $U$ then $\lambda$ is automatically holomorphic in $U$, with $\lambda' (z)=\frac{1}{z}$.
\end{proposition}
\begin{proof}
      If $w \in U$ then 
      \begin{align*}
           \lim_{z \rightarrow w} \frac{\lambda (z)- \lambda (w)}{z-w}&=\lim_{z \rightarrow w} \frac{1}{\left( \frac{e^{\lambda (z)}-e^{\lambda (w)}}{\lambda (z)- \lambda (w)}\right)}\\
           &=\frac{1}{e^{\lambda (w)}}\lim_{z \rightarrow w} \frac{1}{\left(\frac{e^{\lambda (z)-\lambda (w)}-1}{\lambda (z)- \lambda (w)}\right)}\\
           &=\frac{1}{e^{\lambda (w)}} \lim_{h \rightarrow 0} \frac{1}{\left( \frac{e^{h}-1}{h}\right)} \quad \text{ since } \lambda \text{ is continuous } \\
           &=\frac{1}{e^{\lambda (w)}}=\frac{1}{w}.
      \end{align*}
\end{proof}
\begin{definition*}[Principal branch of logarithm]
      The principal branch of logarithm is the function \[
      \operatorname{Log}: U_1 =\mathbb{C} \backslash \left\{x \in \mathbb{R}: \ x \leq 0\right\} \rightarrow \mathbb{C}
      .\] defined by \[
      \operatorname{Log}(z)= \operatorname{log}|z|+i \operatorname{arg}(z)
      .\] where $\operatorname{arg}(z)$ is the unique argument of $z \in U_1 $ in $(-\pi,\pi)$.
\end{definition*}
\begin{remark}
     $\operatorname{Log}$ is a branch of logarithm in $U_{1}:$ to check continuity of $\operatorname{Log}$, note that
     $z \mapsto \log |z|$ is continuous on $\mathbb{C} \backslash\{0\}$ (by continuity of $z \mapsto|z|$ and
     continuity of $r \mapsto \log r$ for $r>0$ ); also, $z \mapsto \arg (z)$ is continuous, since
     $\theta \mapsto e^{i \theta}$ is a homeomorphism $(-\pi, \pi) \rightarrow \mathbb{S}^{1} \backslash\{-1\}$ (as can be checked
     directly, where $\left.\mathbb{S}^{1}=\{z:|z|=1\}\right)$, and $z \mapsto \frac{z}{|z|}$ is continuous on
     $\mathbb{C} \backslash\{0\} .$ So $z \mapsto \log (z)$ is continuous on $U_{1}$.
     We also have \[
          e^{\operatorname{Log} (z)}=e^{\ln |z|+i \arg (z)}=e^{\ln |z|} \cdot e^{i \text { arg }(z)}=
          |z|(\cos \arg (z)+i \sin \arg (z))=z
     .\]  So $\operatorname{Log}$ is a branch of logarithm in $U_{1}$.
\end{remark}
\begin{remark}
      $\operatorname{Log}$ does not have a continuous extension to $\mathbb{C} \backslash\{0\}$ since $\arg (z) \rightarrow \pi$ as $z \rightarrow-1$ with $\operatorname{Im}(z)>0$, and $\arg (z) \rightarrow-\pi$ as $z \rightarrow-1$ with $\operatorname{Im}(z)<0$.
\end{remark}
\begin{proposition}
      \begin{itemize}
           \item[(i)] Log is holomorphic on $U_1 $ with $\operatorname{Log}' (z)=\frac{1}{z}$. 
           \item[(ii)] For $|z|<1$, we have \[
           \operatorname{Log}(1+z)=\sum_{n=1}^{ \infty} \frac{(-1)^{n-1}z^{n}}{n}
           .\] 
      \end{itemize} 
\end{proposition}
\begin{proof}
      \begin{itemize}
           \item[(i)] is the remark above. 
           \item[(ii)] To see this, note that the R.O.C of the series is 1, and $|z|<1 \implies 1+z \in U_1 $, so both sides are defined on $|z|<1$. 
           
           Let $F (z)=\operatorname{Log}(1+z)-\sum_{n=1}^{ \infty} \frac{(-1)^{n-1}z^{n}}{n}$ for $|z|<1$. Then \[
           F' (z)= \frac{1}{1+z}-\sum_{n=1}^{ \infty}(-z)^{n-1}=0
           .\] So $F (z)=\text{ constant } =F (0)=0$.
      \end{itemize}
\end{proof}
Using exp and Log we can define further useful functions. 
\begin{enumerate}
     \item For any $\alpha \in \mathbb{C}$, define \[
     z^{\alpha}=e^{\alpha \operatorname{Log}(z)}, \quad z \in U_1 
     .\] This is the principal branch of $z^{\alpha}$. It's holomorphic on $U_1 $ with derivative $\alpha z^{\alpha-1}$. 
     \item We can define the familiar functions 
     \begin{itemize}
          \item $\cos (z)= \frac{e^{iz}+e^{-iz}}{2}$ 
          \item $\sin (z)= \frac{e^{iz}-e^{-iz}}{2i}$ 
          \item $\cosh (z)= \frac{e^{z}+e^{-z}}{2}$ 
          \item $\sinh (z)= \frac{e^{z}-e^{-z}}{2}$ 
     \end{itemize}
     These are all entire since exp is entire, with derivatives given by the familiar expressions from real variables.
\end{enumerate}
\subsection{Conformality}
Let $f: U \rightarrow \mathbb{C}$ be holomorphic ($U \subset C $ is open). Let $w \in U$ and suppose that $f' (w) \neq 0$. Take two $C^{1}$ curves $\gamma_1 , \gamma_2 : [-1,1] \rightarrow U$ such that $\gamma_1 (0)=\gamma_2 (0)=w$ and with nonzero derivative. Then $f \circ \gamma_i$ are $C^{1}$ curves passing through $f (w)$. Moreover, $(f \circ \gamma_i)' (0)=f' (w)\gamma_{i}' (0)\neq 0$. Thus \[
\frac{(f \circ \gamma_1 )' (0)}{(f \circ \gamma_2 )' (0)}= \frac{\gamma_1 ' (0)}{\gamma_2 ' (0)}
.\]
Hence \[
\operatorname{arg}(f \circ \gamma_1 )' (0)-\operatorname{arg}(f \circ \gamma_2 )' (0)=\operatorname{arg}\gamma_1 ' (0)-\operatorname{arg}\gamma_2 ' (0)
.\] This means that the angle that the curves $\gamma_1 , \gamma_2 $ make at $w$ is the same as the angle their images make at $f (w)$. We say f is `angle-preserving at $w$', whenever $f' (w) \neq 0$.
\begin{remark}
      If $f$ is a $C^{1}$ map on $U$, the converse of this also holds. See Example Sheet 1. 
\end{remark}
\begin{definition*}[Conformal map]
      A holomorphic function $f: U \rightarrow \mathbb{C}$ on an open set $U$ is said to be \vocab{conformal} at a point $w \in U$ if $f' (w) \neq 0$.
\end{definition*}
\begin{definition*}[Conformal equivalence]
      Let $U, \widetilde{U} $ be domains in $\mathbb{C}$. A map $f: U \rightarrow \widetilde{U}$ is said to be a conformal equivalence between $U$ and $\widetilde{U}$ if f is a bijective holomorphic map with $f' (z) \neq 0$ for every $z \in U$.
\end{definition*}
\begin{remark}
      \begin{itemize}
           \item If $f$ is holomorphic and injective, then $f' (z) \neq 0$ for each $z$. We will prove this later. So in the above definition $f' (z) \neq 0$ is redundant. 
           \item It is automatic that the inverse ${f}^{-1}: U \rightarrow \widetilde{U}$ is holomorphic. This can be proved using the holomorphic inverse function theorem, which you will prove on Example Sheet 1.
      \end{itemize}
\end{remark}
\begin{example*}
     Let's look at some examples of conformal equivalence.
      \begin{enumerate}
           \item Mobius maps are defined for $a,b,c,d \in \mathbb{C}$ with $ad-bc \neq 0$ (see IA Groups): \[
           f (z)= \frac{az+b}{cz+d}
           .\] Mobius maps sometimes serve as explicit conformal equivalences between subdomains of $\mathbb{C}$. For example, let $\mathbb{H}$ be the open upper half plane. Then 
           \begin{align*}
                z \in \mathbb{H} &\iff |z-i| < |z+i|\\
                & \iff | \frac{z-i}{z+i}|<1.
           \end{align*}
           Thus $g (z)=\frac{z-i}{z+i}$ maps $\mathbb{H}$ onto $D (0,1)$, so $g$ is a conformal equivalence.
           \item Consider $f: z \rightarrow z^{n}$ where $n \in \mathbb{N}$ where $f: \left\{z \in C \backslash \left\{0\right\}: 0 < \operatorname{arg}(z) < \frac{\pi}{n}\right\} \rightarrow \mathbb{H}$. This is a conformal equivalence with inverse $f (z)=z^{1/n}$ (the principal branch).
           \item We have that \[
           \operatorname{exp}: \left\{z \in \mathbb{C}: \ -\pi < \operatorname{Im}(z)<\pi\right\} \rightarrow \mathbb{C} \backslash \left\{x \in \mathbb{R}: x \leq 0\right\}
           .\]  
      \end{enumerate}
\end{example*}
Aside:
\begin{theorem}[Riemann Mapping Theorem]
      Any simply connected domain $U \subset \mathbb{C}$ with $U \neq \mathbb{C}$ is conformally equivalent to $D (0,1)$.
\end{theorem}
\begin{proof}
      This is beyond the scope of the course.\footnotemark
\end{proof}\footnotetext{See Rudin's \emph{Real and Complex Analysis}.}
\section{Complex Integration: Part I}
\subsection{Definitions and basic properties}
We aim to extend Riemann integration to complex functions $f: U \rightarrow \mathbb{C}$ along curves in $U$. First we take a look at complex functions of a real variable. 
\begin{definition*}
      If $f: [a,b] \subset \mathbb{R} \rightarrow C$ is a complex function and if $f$ is Riemann integrable, define \[
      \int_{a}^{b}f (t) \mathrm{d}t= \int_{a}^{b}\operatorname{Re} f (t) \mathrm{d}t+ \int_{a}^{b}\operatorname{Im}f (t) \mathrm{d}t   
      .\] In particular, \[
      \int_{a}^{b}i f (t) \mathrm{d}t =i \int_{a}^{b}f (t) \mathrm{d}t  
      .\] We can then directly calculate for any $w \in \mathbb{C}$ that \[
          \int_{a}^{b}w f (t) \mathrm{d}t =w\int_{a}^{b}f (t) \mathrm{d}t 
      .\] 
\end{definition*}
\begin{proposition}
      If $f: [a,b] \rightarrow \mathbb{C}$ is continuous, then \[
      |\int_{a}^{b} f (t) \mathrm{d}t | \leq \int_{a}^{b} |f (t)| \mathrm{d}t \leq (b-a) \sup_{t \in [a,b]} |f (t)|
      ,\] with equality iff $f$ is constant. 
\end{proposition}
\begin{proof}
      If $\int_{a}^{b}f (t) \mathrm{d}t $ then we are done. Else write $\int_{a}^{b}f (t) \mathrm{d}t= re^{i \theta} $ for some $\theta \in [0,2\pi)$ and let $M=\sup_{t \in [a,b]} |f (t)|$. Then 
      \begin{align*}
           |\int_{a}^{b}f (t) \mathrm{d}t| &=r= e^{-i \theta}\int_{a}^{b}f (t) \mathrm{d}t=\int_{a}^{b}e^{-i \theta}f (t) \mathrm{d}t\\
           &=\int_{a}^{b}\operatorname{Re}(e^{-i \theta}) f (t) \mathrm{d}t+ \int_{a}^{b} \operatorname{Im}(e^{-i \theta})f (t) \mathrm{d}t. 
      \end{align*}
      Since the LHS is real, \[
      |\int_{a}^{b}f (t) \mathrm{d}t|=\int_{a}^{b}\operatorname{Re} f (t) \mathrm{d}t \leq  \int_{a}^{b}|e^{-i \theta} f (t)| \mathrm{d}t=\int_{a}^{b}| f (t)| \mathrm{d}t\leq (b-a)M
      .\] 
      Equality holds iff $|f (t)|=M$ and $\operatorname{Re} (e ^{-i \theta}f (t))=M$ for all $t \in [a,b]$, i.e iff $|f (t)|=M$ and $\operatorname{arg} f (t)= \theta$ for all $t$; iff $f$ constant.
\end{proof}
\begin{definition*}[Integral along a curve]
      Let $U \subset \mathbb{C}$ be open and $f: U \rightarrow \mathbb{C}$ be continuous. Let $\gamma: [a,b] \rightarrow U$ be a $C^1$ curve. Then the \vocab{integral of $f$ along $\gamma$} is \[
      \int_{\gamma}^{}f (z) \mathrm{d}z= \int_{a}^{b} f (\gamma (t))\gamma' (t) \mathrm{d}t  
      .\]
\end{definition*}
\begin{proposition}[Basic properties of the integral]
      If we have the integral of $f$ along $\gamma$, we have the following properties: 
      \begin{enumerate}
           \item Invariance under reparametrisation: Let $\varphi: [a_1 ,b_1 ] \rightarrow [a,b]$ be $C^1$ and injective with $\varphi (a_1 )=a, \varphi (b_1 )=b.$ Let $\delta= \gamma \circ \varphi : [a_1 ,b_1] \rightarrow U$. Then we have \[
           \int_{\delta}^{}f (z) \mathrm{d}z= \int_{\gamma}^{}f (z) \mathrm{d}z  
           .\]  
           \item Linearity: \[
           \int_{\gamma}^{}c_1 f_1 (z)+ c_2 f_2 (z) \mathrm{d}z= c_1 \int_{\gamma}^{}f_1 (z) \mathrm{d}z +c_2  \int_{\gamma}^{}f_2 (z) \mathrm{d}z 
           .\] 
           \item Additivity: If $\gamma$ is our $C^1$ curve and $a<c<b$, then \[
           \int_{\gamma}^{}f (z) \mathrm{d}z = \int_{\gamma|_[a,c]}^{}f (z) \mathrm{d}z + \int_{\gamma|_[c,b]}^{}f (z) \mathrm{d}z  
           .\] 
           \item Inverse path: Define the inverse path $(-\gamma):[-b,-a] \rightarrow U$ by $(-\gamma)(t)=\gamma(-t)$ for $-b \leq t \leq-a$. Then
           $$
           \int_{(-\gamma)} f(z) d z=-\int_{\gamma} f(z) \mathrm{d} z
           $$
      \end{enumerate}
\end{proposition}
\begin{proof}
     For 1, we have 
     \begin{align*}
          \int_{\delta}^{}f (z) \mathrm{d}z &= \int_{a_1 }^{b_1 }f (\upsilon \circ \varphi (t)) \gamma' (\varphi (t))\varphi' (t) \mathrm{d}t \\
          &=\int_{a}^{b}f (\gamma (s))\gamma' (s) \mathrm{d}s = \int_{\gamma}^{}f (z) \mathrm{d}z \quad \text{ by change of vars. } s=\varphi (t).
      \end{align*}
      2,3, and 4 are all easy to check from the definition.
\end{proof}
\begin{definition*}[Length of a curve]
     Definition: Let $\gamma:[a, b] \rightarrow \mathbb{C}$ be a $C^{1}$ curve. The length of $\gamma$ is defined by
     $$
     \operatorname{length}(\gamma)=\int_{a}^{b}\left|\gamma^{\prime}(t)\right| d t.
     $$
\end{definition*}
\begin{definition*}
      A \vocab{piecewise $C^1$ curve} is a continuous map $\gamma: [a,b] \rightarrow \mathbb{C}$ such that there exists a finite subdivision \[
      a=a_0 <a_1 < \ldots <a_{n-1}<a_{n}=b
      \] with the property that $\gamma_{j}=\gamma|_{[a_{j-1},a_j]}: \ [a_{j-1},a_j] \rightarrow \mathbb{C}$ is $C^{1}$ for all $1 \leq j \leq n$. We define \[
      \int_{\gamma}^{}f (z) \ \mathrm{d} z= \sum_{j=1}^{n} \int_{\gamma_{j}}^{}f (z) \ \mathrm{d}z 
      .\] 
      and \[
          \operatorname{length}(\gamma)=\sum_{j=1}^{n}\operatorname{length}(\gamma_{j})=\sum_{j=1}^{n}\int_{a_{j-1}}^{a_j}|\gamma' (t)| \ \mathrm{d}t 
      .\] 
\end{definition*}
\begin{remark}
      From now on, by a `curve' we shall mean a piecewise $C^{1}$ curve.
\end{remark}
\begin{definition*}
     If $\gamma_{1}:[a, b] \rightarrow \mathbb{C}$ and $\gamma_{2}:[c, d] \rightarrow \mathbb{C}$ are curves with $\gamma_{1}(b)=\gamma_{2}(c)$, we define the sum of of $\gamma_{1}$ and $\gamma_{2}$ to be the curve \[
          \left(\gamma_{1}+\gamma_{2}\right): [a, b+d-c] \rightarrow \mathbb{C}
     ,\] 
     \begin{equation*}
          \left(\gamma_{1}+\gamma_{2}\right)(t)=
           \begin{cases}
               \gamma_{1}(t) & a \leq t \leq b \\
               \gamma_{2}(t-b+c) & b \leq t \leq b+d-c
          \end{cases}
     \end{equation*}
\end{definition*}
\begin{proposition}\label{basicestimate}
     For any continuous function $f: U \rightarrow \mathbb{C}$ and any curve $\gamma:[a, b] \rightarrow \mathbb{C}$, we have that
     $$
     \left|\int_{\gamma} f(z) d z\right| \leq \text { length }(\gamma) \sup _{\gamma}|f|
     $$
     where $\sup _{\gamma}|f|=\sup _{t \in[a, b]}|f(\gamma(t))|$.
\end{proposition}
\begin{proof}
     If $\gamma$ is $C^{1}$, then \[
          \left|\int_{\gamma} f(z) d z\right|=\left|\int_{a}^{b} f(\gamma(t)) \gamma^{\prime}(t) d t\right| \leq
          \int_{a}^{b}\left|f(\gamma(t)) \| \gamma^{\prime}(t)\right| d t \leq \sup _{t \in[a, b]}|f(\gamma(t))|\operatorname{length}(\gamma)
     .\] If $\gamma$ is piecewise $C^{1}$ then the result follows from the definition $\int_{\gamma} f(z) d z=\sum_{j=1}^{n} \int_{\gamma_{j}} f(z) d z$ where $\gamma_{j}$ is $C^{1}$, and the triangle inequality.
\end{proof}
\subsection{Fundamental theorem of calculus}
We can now look at the complex version of the FTC.
\begin{theorem}[Fundamental Theorem of Calculus]\label{ftc}
     Suppose that $f: U \rightarrow \mathbb{C}$ is continuous, $U \subset \mathbb{C}$ open. If there is a function $F: U \rightarrow \mathbb{C}$ such that $F^{\prime}(z)=f(z)$ for all $z \in U$, then for any curve $\gamma:[a, b] \rightarrow U$,
     $$
     \int_{\gamma} f(z) d z=F(\gamma(b))-F(\gamma(a)) .
     $$
     If additionally $\gamma$ is a closed curve, i.e. $\gamma(b)=\gamma(a)$, then $\int_{\gamma} f(z) d z=0$.
\end{theorem}
\begin{proof}
     This follows immediately:
      \[
          \int_{\gamma} f(z) d z=\int_{a}^{b} f(\gamma(t)) \gamma^{\prime}(t) d t=\int_{a}^{b} \frac{d}{d t} F(\gamma(t)) d t=F(\gamma(b))-F(\gamma(a))
      .\] 
\end{proof}
\begin{remark}
     Such $F$ as in Theorem $2.3$ is called an \vocab{anti-derivative} of $f$.
     
     We shall see later (by infinite differentiability of holomorphic functions) that if $F^{\prime}(z)=f(z)$, then $f$ is automatically continuous.
\end{remark}
\begin{example*}
      Let $\int_{\gamma}^{}z^{n} \ \mathrm{d}z $ for $n \in \mathbb{Z}$, where $\gamma: [0,1]\rightarrow \mathbb{C}$, $\gamma (t)=R e^{2\pi it}$ for some $R>0$. (The image of $\gamma$ is the circle of radius $R$ centred at 0). 

      For $n \neq 1$, $ \frac{z^{n+1}}{n+1}$ is an antiderivative of $z^{n}$ in $\mathbb{C}\backslash \left\{0\right\}$, so by the FTC, $\int_{\gamma}^{}z^{n} \ \mathrm{d}z =0$ since $\gamma$ is a closed curve.

      For $n=-1$, use the definition of the integral: \[
          \int_{\gamma}^{}\frac{1}{z} \ \mathrm{d}z =\int_{0}^{1} \frac{\gamma' (t)}{\gamma (t)} \ \mathrm{d}t=\int_{0}^{1} \frac{2 \pi iR e^{2\pi it}}{R e^{2\pi it}} \ \mathrm{d}t= 2 \pi i
      .\] 
      Since $\int_{\gamma} \frac{1}{z} d z \neq 0$, we can conclude that for any $R>0, \frac{1}{z}$ has no anti-derivative in any open set containing the circle $\{|z|=R\}$.

      In particular, since for any branch $\lambda(z)$ of logarithm the derivative $\lambda^{\prime}(z)=\frac{1}{z}$, there is no branch of logarithm on $\mathbb{C}^{\star}=\mathbb{C} \backslash\{0\} .$
\end{example*}
\begin{theorem}[Converse to FTC]\label{ftcconverse}
      Let $U \subset \mathbb{C}$ be a domain. If $f: U \rightarrow \mathbb{C}$ is continuous and if $\int_{\gamma}^{}f (z) \ \mathrm{d}z =0$ for every closed curve $\gamma$ in $U$, then $f$ has an antiderivtive, i.e there is a holomorphic function $F: U \rightarrow \mathbb{C}$ such that $F' (z)=f (z)$ for each $z \in U$.
\end{theorem}
\begin{proof}
      Fix $a_0 \in U$. For $w \in U$, define \[
      F (w) \int_{\gamma_{w}}^{}f (z) \ \mathrm{d}z 
      .\] where $\gamma_{w}: [0,1] \rightarrow \mathbb{C}$ is a curve with $\gamma_{w} (0)=a_0 , \ \gamma_{w}(1)=w$ (exists since $U$ is path-connected). The definition of $F$ is independent of the chocie of $\gamma_{w}$ by our hypothesis that $\int_{\gamma}^{}f (z) \ \mathrm{d}z =0$ for every closed curve $\gamma$ in $U$. So $F: U \rightarrow \mathbb{C}$ is well-defined.

      Fix $w \in U$. Since $U$ is open, there is $r>0$ such that $D (w,r) \subset  U$. For $h \in \mathbb{C}$ with $0 < |h|<r$, let $\delta_{h}$ be the straight line path $t \mapsto w+th$ for $t \in [0,1]$. Let \[
      \gamma= \gamma_{w}+\delta_{h}+ (-\gamma_{w+h})
      .\] $\gamma$ is closed so $\int_{\gamma}^{}f \ \mathrm{d}z=0 $. Thus \[
      \int_{\gamma_{w+h}}^{}f (z) \ \mathrm{d}z =\int_{\gamma_{w}}^{}f (z) \ \mathrm{d}z +int_{\delta_{h}}^{}f (z) \ \mathrm{d}z 
      .\] In terms of $F$, this says that \[
     F (w+h)=F (w)+int_{\delta_{h}}^{}f (z) \ \mathrm{d}z =F (w)+ h f (w)+int_{\delta_{h}}^{}f (z)-f (w) \ \mathrm{d}z 
      .\] So 
      \begin{align*}
           \left| \frac{F (w+h)-F (w)}{h}- f (w)\right| &= \frac{1}{|h|}|int_{\delta_{h}}^{}f (z)-f (w) \ \mathrm{d}z |\\
           &\leq \frac{1}{|h|}\operatorname{length}(\delta_{h})\sup_{z}|f (z)-f (w)|\\
           &=\sup_{z}|f (z)-f (w)|\\
           & \rightarrow 0 \text{ as } h \rightarrow 0 \quad \text{ since } f \text{ is continuous.}
      \end{align*}
      Therefore $F$ is differentiable at $w$ with $F' (w)=f (w)$.
\end{proof}
The FTC is true for any domain, but next we restrict ourselves to a smaller subset of domains and prove some results for domains of certain shapes.
\begin{definition*}[Star-shaped domain]
      A domain $U$ is \vocab{star-shaped} if there is $a_0 \in U$ such that got each $w \in U$, the straight-line segment $[a_0 ,w] \subset U$.
\end{definition*}
\begin{remark}
      $U$ is a disk $\implies $ $U$ is convex $\implies $ $U$ is star-shaped $\implies $ $U$ is path-connected. None of the reverse implications hold.
      \begin{figure}[H]
           \centering
           \incfig{85}{star-drawing}
      \end{figure}
      
\end{remark}
\begin{definition*}[Triangle]
      A \vocab{traingle} in $\mathbb{C}$ is the convex hull of three points in $\mathbb{C}$. The three points are the vertices of the triangle.
\end{definition*}
\begin{notation}
     For a triangle $T$, we write $\int_{\partial T}^{}f (z) \ \mathrm{d}z $ to denote the integral of $f$ along the piecewise affine closed curve $\gamma=\gamma_1 +\gamma_2 +\gamma_3 $ where $\gamma_1 , \gamma_2 , \gamma_3 $ parameterise the three straight lines that are the sides of $T$ with the interior of $T$ to the left of them.
\end{notation}
\begin{corollary}[of Theorem \ref{ftcconverse}]\label{starantideriv}
      If $U$ is star-shaped, $f: U \rightarrow \mathbb{C}$ is continuous and $\int_{\partial T}^{}f (z) \ \mathrm{d}z =0$ for any triangle $T \subset U$, then $f$ has an antiderivative in $U$.
\end{corollary}
\begin{proof}
      Suppose $U$ is star-shaped with respect to a point $a_0 \in U$ and let $w \in U$ be some point. Let $\gamma_{w}$ be the function parameterising $[a_0 ,w]$ and let $F (w)=\int_{\gamma_{w}}^{}f (z) \ \mathrm{d}z .$ With $h, \delta_{h}$ and $\gamma$ as in the proof of Theorem \ref{ftcconverse}, we then have that $\int_{\gamma} f(z) d z=\pm \int_{\partial T} f(z) d z$ for a triangle $T \subset U$ (with the - sign if $T$ lies to the right of the directed boundary segments).
      Since $\int_{\partial T} f(z) d z=0$ by hypothesis, we have that $\int_{\gamma} f(z) d z=0$. We can now proceed exactly as in the proof of Theorem \ref{ftcconverse}.
\end{proof}
We will soon see that the validity of $\int_{\gamma}^{}f (z) \ \mathrm{d}z=0 $ for any holomorphic $f$ on $U$ and any curve $\gamma$ in $U$ has important consequences.

One of our goals in the course will be to characterise these domains $U$. We are going to build towards Cauchy's theorem, which states that this is true for simply connected $U$.

The next object of discussion is an elegant proof of Cauchy's theorem restricted to the special case of triangles in $\mathbb{C}$.
\begin{theorem}[Cauchy's theorem for triangles]\label{cauchytriangle}
      Let $U \subset \mathbb{C}$ be open and $f: U \rightarrow \mathbb{C}$ be holomorphic. Then $\int_{\partial T}^{}f (z) \ \mathrm{d}z=0 $ for any triangle $T \subset U$.
\end{theorem}
\begin{proof}
      Let $\eta (T)=\int_{\partial T}^{}f (z) \ \mathrm{d}z$.
      
      \emph{First key idea:} subdivide $T$ into four smaller triangles $T^{(1)},T^{(2)},T^{(3)},T^{(4)}$ by joining the midpoints of the sides of T:
      
      \incfig{40}{4triangles}
      
      Note that \[
          \eta(T)=\int_{\partial T(1)} f(z) d z+\int_{\partial T(2)} f(z) d z+\int_{\partial T(3)} f(z) d z+\int_{\partial T^{(4)}} f(z) d z
      .\] 
     So by the triangle inequality,
     $$
     \left|\int_{\partial T^{(j)}} f(z) d z\right| \geq \frac{|\eta(T)|}{4}
     $$
     for some $j \in\{1,2,3,4\}$. Let $T_{1}=T^{(j)}$ for this $j$, and write $T_{0}=T$. So $\left|\eta\left(T_{1}\right)\right| \geq \frac{1}{4}\left|\eta\left(T_{0}\right)\right|$. Also, length $\left(\partial T_{1}\right)=\frac{1}{2}$ length $\left(\partial T_{0}\right)$.
     Now repeat the process: subdivide $T_{1}$ and choose a new triangle $T_{2} \subset T_{1}$ exactly the same way. Doing this indefinitely generates a sequence of triangles $T_{0} \supset T_{1} \supset T_{2} \supset \ldots$ satisfying, for $n=1,2,3, \ldots$, \[
     |\eta (T_{n})| \geq \frac{1}{4}|\eta (T_{n-1})| \text{ and } \operatorname{length}(\partial T_{n})=\frac{1}{2}\operatorname{length}(\partial T_{n-1})
     .\] Iterating, we get \[
          |\eta (T_{n})|=\geq \frac{1}{4^{n}}|\eta (T_{0})| \text{ and } \operatorname{length}(\partial T_{n})=\frac{1}{2^{n}}\operatorname{length}(\partial T_{0})
     .\] Since $T_{n}$ are non-empty, nested closed subsets with $\operatorname{diam}(T_{n})\rightarrow 0$ and $\mathbb{C}$ is a complete metric space, we have that $\bigcup_{n=1}^{ \infty}T_{n}=\left\{z_0 \right\}$ for some $z_0 \in \mathbb{C}$ (Analysis \& Topology sheet 3).

     Now let $\varepsilon >0$. Since $f$ is differentiable at $z_0 $, there is $\delta >0$ such that for all $z \in U$, \[
     |z-z_0 |<\delta \implies |f (z)-f (z_0 )-f' (z_0 )(z-z_0 )| < \varepsilon |z-z_0 |
     .\] \emph{Second key idea:} observe that for any $n$, \[
          \int_{\partial T_{n}} f(z) d z=\int_{\partial T_{n}}\left(f(z)-f\left(z_{0}\right)-f^{\prime}\left(z_{0}\right)\left(z-z_{0}\right)\right) d z
     \] (since $\int_{\partial T_{n}} 1 d z=\int_{\partial T_{n}} z d z=0$, by the FTC). 
     
     So choosing $n$ with $T_{n} \subset D\left(z_{0}, \delta\right)$ (which is possible since $z_{0} \in T_{n}$ for all $n$ and $\operatorname{diam}\left(T_{n}\right) \rightarrow 0$),
     \begin{align*}
          \frac{1}{4^{n}}\left|\eta\left(T_{0}\right)\right| &\leq\left|\eta\left(T_{n}\right)\right|=\left|\int_{\partial T_{n}} f(z) d z\right|\\
          &=\left|\int_{\partial T_{n}}\left(f(z)-f\left(z_{0}\right)-f^{\prime}\left(z_{0}\right)\left(z-z_{0}\right)\right) d z\right|\\
          &\leq\left(\sup _{z \in \partial T_{n}}\left|f(z)-f\left(z_{0}\right)-f^{\prime}\left(z_{0}\right)\left(z-z_{0}\right)\right|\right) \operatorname{length}\left(\partial T_{n}\right)\\
          &=\leq \epsilon\left(\sup _{z \in \partial T_{n}}\left|z-z_{0}\right|\right)\operatorname{length}\left(\partial T_{n}\right) \leq \epsilon\left(\operatorname{length}\left(\partial T_{n}\right)\right)^{2}\\
          &=\frac{\epsilon}{4^{n}}\left(\operatorname{length}\left(\partial T_{0}\right)\right)^{2}.
     \end{align*}
     Cancel $\frac{1}{4^{n}}$ on both sides and let $\epsilon \rightarrow 0$. This gives $\eta\left(T_{0}\right)=0$.
\end{proof}
For later applications, we want to generalise this theorem to continuous functions which are assumed holomorphic \emph{except at a finite number of points}.
\begin{theorem}
      Let $U \subset \mathbb{C}$ be open and $f: U \rightarrow \mathbb{C}$ be continuous. Let $S \subset U$ be a finite set and suppose that $f$ is holomorphic on $U\backslash S$. Then \[
      \int_{\partial T}^{}f (z) \ \mathrm{d} z =0 \quad \text{ for every triangle } T \subset U
      .\] 
\end{theorem}
\begin{proof}
      Subdivide $T$ into a total of $N=4^{n}$ smaller triangles by the iterative procedure before, where at each step we join up the midpoints of the sides of the triangles at the previous step. This time we keep all the smaller triangles; call them $T_1 , T_2 , \ldots , T_N$. (Note the notational difference from before.) Then since the integrals along the sides of the smaller triangles that are interior to $T$ cancel, we get that \[
      \int_{\partial T}^{}f (z) \ \mathrm{d}z = \sum_{j=1}^{N} \int_{ \partial T_{j}}^{}f (z) \ \mathrm{d}z
      .\] Note by the previous theorem that $\int_{ \partial T_{j}}^{}f (z) \ \mathrm{d}z=0$ unless $T_{j}\cap S \neq \emptyset$. So letting $I=\left\{j: T_{j} \cup S = \emptyset\right\}$, we have that $\int_{\partial T}^{}f (z) \ \mathrm{d}z=\sum_{j \in I}^{}\int_{ \partial T_{j}}^{}f (z) \ \mathrm{d}z$. Since any point can be in at most 6 smaller triangles and $\operatorname{length}( \partial T_{j})=\frac{1}{2^{n}}\operatorname{length} ( \partial T)$, we get that \[
      \left|\int_{ \partial T}^{}f (z) \ \mathrm{d}z \right| \leq 6 \left|S\right|\left(\sup_{z \in T} \left|f (z)\right|\right) \frac{\operatorname{length} ( \partial T)}{2^{n}}
      .\] Then let $n \rightarrow \infty$ and we are done.
\end{proof}
\begin{corollary}(Convex Cauchy)\label{convexcauchy}
      Let $U \subset C$ be convex, or more generally, a star domain. Let $f: U \rightarrow \mathbb{C}$ be continuous and holomorphic in $U \backslash S$ where $S$ is a finite set. Then $\int_{\gamma}^{}f (z) \ \mathrm{d}z=0 $ for any closed curve $\gamma$ in $U$.
\end{corollary}
\begin{proof}
      By Theorem \ref{cauchytriangle}, $\int_{ \partial T}^{} f (z)\ \mathrm{d}z=0 $ for any triangle $T \subset U$. Since $U$ is a star domain and $f$ is continuous, this means that by Corollary \ref{starantideriv} that $f$ has an antiderivative in $U$. The result now follows from the FTC.
\end{proof}
Now we are ready to draw a series of very nice corollaries of "convex Cauchy". The main corollary is a representation formula known as the \emph{Cauchy integral formula}, from which the other results will follow.
\subsection{Cauchy integral formula}
\begin{notation}
     For a disk $D (a,\rho)$ we will write $\int_{ \partial D (a, \rho)}^{}f (z) \ \mathrm{d}z $ to mean $\int_{\gamma}^{}f (z) \ \mathrm{d}z $ where $\gamma$ is the curve $\gamma (t)=a+\rho e^{2\pi i t}$ (which parameterises the boundary of the disk with positive orientation, i.e so that the disk lies to the left of the directed boundary circle). 
\end{notation}
\begin{theorem}[Cauchy integral formula for a disk]
      Let $D=D (a,r)$ and let $f: D \rightarrow \mathbb{C}$ be holomorphic. Then for any $\rho$ with $0 < \rho< r$ and any $w \in D (a, \rho)$ wehave that \[
      f (w)=\frac{1}{2\pi i} \int_{ \partial D (a, \rho)}^{} \frac{f (z)}{z-w} \ \mathrm{d}z
      .\] In particular (taking $w=a$), \[
          f (a)=\frac{1}{2\pi i} \int_{ \partial D (a, \rho)}^{} \frac{f (z)}{z-a} \ \mathrm{d}z= \int_{0}^{1}f (a+ \rho e^{2\pi it}) \ \mathrm{d}t 
      .\] This is called the \emph{mean value property} for holomorphic functions.
\end{theorem}
For the proof we will need the following fact:
\begin{lemma}
      If $\gamma: [a,b] \rightarrow \mathbb{C}$ is a curve and $\left(f_{n}\right)$ is a sequence of continuous complex functions on image $(\gamma)$ converging uniformly to a function $f$ on image $(\gamma)$, then $\int_{\gamma} f_{n}(z) d z \rightarrow \int_{\gamma} f(z) d z$.
      This is true because
      $$
      \begin{array}{r}
      \left|\int_{\gamma} f_{n}(z) d z-\int_{\gamma} f(z) d z\right|=\left|\int_{\gamma}\left(f_{n}(z)-f(z)\right) d z\right| \\
      \leq \sup _{z \in \operatorname{image}(\gamma)}\left|f_{n}(z)-f(z)\right| \operatorname{length}(\gamma)
      \end{array}
      $$
\end{lemma}
Now let's prove the Cauchy integral formula.
\begin{proof}
     Fix $w \in D (a, \rho)$ and define $h: D \rightarrow C$ by 
     \begin{equation*}
           h (z)=
           \begin{cases}
                \frac{f (z)-f (w)}{z-w}& z \neq w\\
                f' (w) & z=w
           \end{cases}
     \end{equation*}
     Then $h$ is continuous on $D$ and holomorphic in $D \backslash \left\{w\right\}$, so by ``convex Cauchy'', \[
     \int_{ \partial D (a,\rho)}^{}h (z) \ \mathrm{d}z=0 
     .\] Substituting for $h$, we get \[
     f (w) \int_{ \partial D (a,\rho)}^{} \frac{1}{z-w} \ \mathrm{d}z=\int_{ \partial D (a,\rho)}^{} \frac{f (z)}{z-w} \ \mathrm{d}z
     .\] Now we just have to show that $\int_{\partial D(a, \rho)} \frac{1}{z-w} d z=2 \pi i$. To do this, note that $\frac{1}{z-w}=\frac{1}{z-a+a-w}=\frac{1}{(z-a)\left(1-\frac{w-a}{z-a}\right)}=\sum_{j=0}^{\infty} \frac{(w-a)^{j}}{(z-a)^{j+1}}$, where the convergence is uniform for $z \in \partial D(a, \rho)$ by the Weierstrass $M$-test (since $\left|\left(\frac{w-a}{z-a}\right)^{j}\right|=\left(\frac{|w-a|}{\rho}\right)^{j} \equiv M_{j}$, and $\left.\sum M_{j}<\infty .\right)$ Therefore, by the above fact, we can interchange summation and integration to get,
     $$
     \int_{\partial D(a, \rho)} \frac{d z}{z-w}=\sum_{j=0}^{\infty}(w-a)^{j} \int_{\partial D(a, \rho)} \frac{1}{(z-a)^{j+1}} d z
     $$
     Now for $j \geq 1$, the function $\frac{1}{(z-a)^{j+1}}$ has an anti-derivative $\left(=-\frac{1}{j(z-a)^{j}}\right)$ in a neighbourhood of $\partial D(a, \rho)$, so by FTC, all integrals on the right for $j \geq 1$ are zero. For $j=0$, by direct computation $\int_{\partial D(a, \rho)} \frac{1}{z-a} d z=2 \pi i$.
     So $\int_{\partial D(a, \rho)} \frac{1}{z-w} d z=2 \pi i$, which concludes the proof.
\end{proof}
This finally gives us the tools to prove two very deep results: Liouville's theorem and the Fundamental Theorem of Algebra.
\begin{theorem}[Liouville's theorem]
      If $f: \mathbb{C} \rightarrow \mathbb{C}$ is entire (holomorphic on $\mathbb{C}$) and bounded, then $f$ is constant. More generally, if $f$ is entire with sub-linear growth (i.e there are constants $K>0$ and $\alpha<1$ such that $\left|f (z)\right|\leq K (1+\left|z\right|^{\alpha})$) for all $z \in \mathbb{C}$, then $f$ is constant. 
\end{theorem}
\begin{proof}
     For any given $w \in \mathbb{C}$ and any $\rho>|w|$, we have by $\mathrm{CIF}$ that $f(w)=\frac{1}{2 \pi i} \int_{\partial D(0, \rho)} \frac{f(z)}{z-w} d z$ and $f(0)=\frac{1}{2 \pi i} \int_{\partial D(0, \rho)}\left(\frac{f(z)}{z} d z\right.$. Thus
     $$
     \begin{aligned}
     |f(w)-f(0)| &=\frac{1}{2 \pi}\left|\int_{\partial D(0, \rho)} \frac{w f(z)}{z(z-w)} d z\right| \\
     & \leq \frac{|w|}{2 \pi} \sup _{z \in \partial D(0, \rho)} \frac{|f(z)|}{|z||| z|-| w||} \operatorname{length}(\partial D(0, \rho)) \\
     & \leq \frac{|w| K\left(1+\rho^{\alpha}\right)}{2 \pi \rho(\rho-|w|)} 2 \pi \rho=\frac{|w| K\left(1+\rho^{\alpha}\right)}{\rho-|w|}
     \end{aligned}
     $$
     Let $\rho \rightarrow \infty$ in this, keeping $w$ fixed to conclude that $f(w)=f(0)$. So we are done.
\end{proof}
\begin{theorem}[Fundamental Theorem of Algebra]
      Every non-constant polynomial with complex coefficients has a complex root.
\end{theorem}
\begin{proof}
     Let $p(z)=a_{n} z^{n}+a_{n-1} z^{n-1}+\ldots+a_{1} z+a_{0}$ be a complex polynomial of degree $n \geq 1$. Then $a_{n} \neq 0$, and for $z \neq 0$ we can write $p(z)=z^{n}\left(a_{n}+\frac{a_{n-1}}{z}+\ldots+\frac{a_{0}}{z^{n}}\right)$. So by the triangle inequality,
     $|p(z)| \geq\left(|z|^{n}\left(\left|a_{n}\right|-\frac{\left|a_{n-1}\right|}{|z|}-\ldots-\frac{\left|a_{0}\right|}{|z|^{n}}\right)\right.$. This implies that we can find
     $R>0$ such that $|p(z)| \geq 1$ for $|z|>R^{\prime}$ (in fact $|p(z)| \rightarrow \infty$ as $\left.|z| \rightarrow \infty\right)$.
     Now if $p(z) \neq 0$ for all $z$, then $g(z)=\frac{1}{p(z)}$ is entire. By the above, $|g(z)| \leq 1$ for $|z|>R$. By continuity of $g$, we also have that $|g(z)|$ bounded from above on the compact set $\{|z| \leq R\}$. Thus $g$ is a bounded entire function, so by Liouville's theorem $g$ is constant. Since $p$ is non-constant, this is impossible. So $p$ must have a zero.
\end{proof}
\begin{theorem}[Local maximum modulus principle]
      If $f: D \left(a,R\right)\rightarrow \mathbb{C}$ is holoorphic and if $\left|f \left(z\right)\right|\leq \left|f \left(a\right)\right| $ for all $z \in D \left(a,R\right)$, then $f$ is constant.
\end{theorem}
\begin{proof}
      By the mean value property, for any $\rho \in \left(0,R\right)$ we have that \[
      f \left(a\right)= \int_{0}^{1} f \left(a+\rho e^{2 \pi  it }\right) \ \mathrm{d}t 
      .\] Therefore \[
      \left|f \left(a\right)\right|=\left|\int_{0}^{1} f \left(a+\rho e^{2 \pi  it }\right) \ \mathrm{d}t \right| \leq \sup_{t\in [0,1]}\left|f \left(a+\rho e^{2 \pi it }\right)\right|\leq \left|f \left(a\right)\right| \text{ by hypothesis }
     .\] Thus both inequalities must be equality. Equality in the first implies that by Proposition \ref{basicestimate}, $f \left(a+\rho e^{2\pi i t}\right)=c_{\rho }$ for constant $c_{\rho }$ and all $t \in [0,1]$. But then by the first inequality $\left|c_{\rho }\right|=\left|f \left(a\right)\right|$ for each $\rho \in \left(0,R\right)$. Thus $\left|f \left(a+\rho e^{2\pi i t}\right)=c_{\rho }\right|$ is constant for all $\rho \in \left(0,R\right)$ and $t \in [0,1]$; i.e $\left|f \left(z\right)\right|$ is constant on $D \left(a,R\right)$. By the Cauchy-Riemann equations (see Example Sheet 1), it follows that $f$ is constant.
\end{proof}
In section \ref{powerseriessection}, we saw that we could construct power series on disks to generate a large class of holomorphic functions. The next result in the course effectively shows us the converse; that all holomorphic functions have a power series on a disk. 
\begin{theorem}[Taylor series]
      Let $f: D \left(a,R\right) \rightarrow \mathbb{C}$ be holomorphic. Then $f$ has a convergent power series representation on $D \left(a,R\right)$. More precisely, there is a sequence of complex numbers $c_0 , c_1 , \ldots$ such that for all $w \in D \left(a,R\right)$, \[
      f \left(w\right)=\sum_{n=0}^{\infty}c_{n} \left(w-a\right)^{n}
      .\] The coefficient $c_{n}$ is given by \[
      c_{n}=\frac{1}{2\pi i}\int_{\partial D \left(a,\rho \right)}^{} \frac{f \left(z\right)}{\left(z-a\right)^{n+1}} \ \mathrm{d}z 
      ,\] for any $\rho \in \left(0,R\right)$.
\end{theorem}
\begin{proof}
      Let $0<\rho <R$. Then for any $w \in D \left(a,\rho \right)$, we have by the Cauchy integral formula that 
      \begin{align*}
           f \left(w\right)&=\frac{1}{2\pi i} \int_{\partial D \left(a,\rho \right)}^{} \frac{f \left(z\right)}{z-w} \ \mathrm{d}z = \frac{1}{2\pi i} \int_{\partial D \left(a,\rho \right)}^{} f \left(z\right)\sum_{n=0}^{\infty} \frac{\left(w-a\right)^{n}}{\left(z-a\right)^{n+1}} \ \mathrm{d}z\\
           &= \sum_{n=0}^{\infty}\frac{1}{2\pi i} \left(w-a\right)^{n}\int_{\partial D \left(a,\rho \right)}^{} \frac{f \left(z\right)}{\left(z-a\right)^{n+1}} \ \mathrm{d}z.
      \end{align*}
      The last equality is true by uniform convergence of the series for $z$in our disk. Write $c_{n}\left(\rho \right)=\frac{1}{2\pi i}\int_{\partial D \left(a,\rho \right)}^{} \frac{f \left(z\right)}{\left(z-a\right)^{n+1}} \ \mathrm{d}z$. Then we know that $f \left(w\right)= =\sum_{n=0}^{\infty}c_{n}\left(\rho \right) \left(w-a\right)^{n}$ for all $w \in D \left(a,\rho \right)$.

      So by Theorem $1.5$, the function $f$ (being given by a power series in $D(a, \rho)$ ) has derivatives of all orders in $D(a, \rho)$, and the coefficient $c_{n}(\rho)=\frac{f^{(n)}(a)}{n !} .$ In particular $c_{n}(\rho)$ is independent of $\rho$, so call it $c_{n}$.

     Since $\rho \in(0, R)$ is arbitrary, we then have that $f(w)=\sum_{n=0}^{\infty} c_{n}(w-a)^{n}$ for all $\overline{w \in D(a, R)}$, where $c_{n}=\frac{f^{(n)}(a)}{n !}=\frac{1}{2 \pi i} \int_{\partial D(a, \rho)} \frac{f(z)}{(z-a)^{n+1}} d z$ for any $\rho \in(0, R)$.
\end{proof}
\begin{corollary}
      If $f$ is holomorphic on an open set $U \subset \mathbb{C}$, then $f$ has derivatives of all orders in $U$ which are themselves holomorphic on $U$. 
\end{corollary}
\begin{proof}
      $f$ has a power series representation near every point, so its derivatives of all orders exist everywhere. This also of course means that the derivatives of all orders are holomorphic.
\end{proof}
\begin{remarks}
      \begin{enumerate}
           \item Suppose $D(a, R) \subset U$. In the proof of Theorem $2.13$ we have established the formula
           $$
           f^{(n)}(a)=\frac{n !}{2 \pi i} \int_{\partial D(a, \rho)} \frac{f(z) d z}{(z-a)^{n+1}}
           $$
           valid for any $\rho \in(0, R)$. This is a special case of a Cauchy integral formula for derivatives (Theorem $2.16$ below).
           \item Taking $n=1$ in the above formula and estimating, we get \[
               \left|f^{\prime}(a)\right| \leq \frac{1}{\rho}\left(\sup _{z \in \partial D(a, \rho)}|f(z)|\right)
           .\]  This estimate can be thought of as a "localisation of Liouville's theorem," and it directly implies Liouville's theorem: if $f$ is entire and bounded, we can choose any $a \in \mathbb{C}$, apply the estimate and let $\rho \rightarrow \infty$ to conclude that $f^{\prime}=0$ on $\mathbb{C}$ and hence $f$ is constant.
      \end{enumerate}
\end{remarks}

A function $f$ (real or complex) is said to be \vocab{analytic} at a point $a$ if $f$ is given by a convergent power series about $a$ in some neighbourhood of $a$. We know that $f$ analytic at $a$ $\implies $ $f$ has derivatives of all orders near $a$.

Corollary 2.14 says that if $f$ is a complex function, then:

f is analytic at $a$ $\iff$ $f$ has complex derivatives of all orders in a
neighborhood of $a$ $\iff$ $f$ is complex differentiable once in a
neighborhood of $a$ (i.e. $f$ is holomorphic at $a$).

For real functions, existence of derivatives of all orders does not imply analyticity.
(e.g. $f: \mathbb{R}\rightarrow R$ defined by $f (x)=e^{-1/x^2}$ for $x \neq 0$ and $f (0)=0$; this function is differentiable to any order and has $f^{(n)}(0)=0$ for all n, so $f$ is not given by a convergent power series near 0.)
\begin{notation}
     From now on we use analytic and holomorphic interchangeably.
\end{notation}
\begin{remarks}
      \begin{enumerate}
          \item Let $U \subset \mathbb{C}$ be open. We now have (from Corollary 2.14) that $f=u+i v$ is holomorphic in $U \Longleftrightarrow u, v$ have continuous (first) partial derivatives in $U$ (i.e. $u, v$ are $C^{1}$ in $U$ ) and $u, v$ satisfy the Cauchy-Riemann equations.
          \item Corollary $2.14$ provides $C^{2}$ regularity of $u$ and $v$ if $f=u+i v$ is holomorphic in $U$. So we now have fully justified that real and imaginary parts of a holomorphic function are harmonic functions.
      \end{enumerate}
      
\end{remarks}

Corollary $2.14$ (higher order differentiability) leads to the following very useful integral criterion for holomorphicity of a continuous function.

\begin{theorem}[Morera's Theorem]\label{morera}
     Let $U \subset \mathbb{C}$ be open. If $f: U \rightarrow \mathbb{C}$ is continuous and $\int_{\gamma} f(z) d z=0$ for every closed curve $\gamma$ in $U$, then $f$ is holomorphic in $U$.
\end{theorem}
\begin{proof}
     By the FTC (Theorem \ref{ftc}), $f$ has an antiderivative $F$ on U. Such $F$ is of course holomorphic. By Corollary $2.14$ then $F$ is twice differentiable in $U$. Since $F^{\prime}=f$, this means that $f$ is holomorphic.
\end{proof}
\begin{corollary}
     Let $U \subset \mathbb{C}$ be open. If $f: U \rightarrow \mathbb{C}$ is continuous and holomorphic in $U \backslash S$ where $S$ is a finite set, then $f$ is holomorphic in $U$.
\end{corollary}
\begin{proof}
     For each $a \in U$ there is $r>0$ such that $D=D(a, r) \subset U$. Since $D$ is convex, we can apply Corollary \ref{convexcauchy} (convex Cauchy) to see that $\int_{\gamma} f(z) d z=0$ for any closed curve in $D$. By Morera's theorem $f$ is holomorphic in $D$.
\end{proof}
As a further application of Taylor series, we next show that zeros of a non-zero holomorphic function are isolated points.

Suppose $f$ is a non-zero holomorphic function on a disk $D=D(a, R)$. Then by the Taylor series theorem, there are constants $c_{n}$ such that \[
     f(z)=\sum_{n=0}^{\infty} c_{n}(z-a)^{n} \text{ for all } z \in D
.\] 
Since $f \not \equiv 0$ in $D$, there is $n$ such that $c_{n} \neq 0 .$ Then \[
     f(z)=(z-a)^{m} g(z)
,\] 
where $g(z)=\sum_{n=m}^{\infty} c_{n}(z-a)^{n-m}$. The function $g$ is holomorphic on $D$ since it is given by a power series, and $g(a)=c_{m} \neq 0$.

\begin{notation}
     If $m \geq 1$, we say that $f$ has a \vocab{zero of order $m$} at $z=a$. From the formula $c_{n}=\frac{f^{(n)}(a)}{n !}$, it is clear that $m$ is the smallest of the positive integers $n$ such that $f^{(n)}(a) \neq 0$.
\end{notation}
Recall that if $S \subset \mathbb{C}$, then a point $w \in S$ is an \vocab{isolated point} of $S$ if there is $r>0$ such that $S \cap D(w, r)=\{w\}$.

\textbf{Unique continuation for analytic functions:}
Consider a holomorphic function $f: D (a,r)\rightarrow \mathbb{C}$ defined on a disk. We know that by the Taylor series theorem, $f$ is uniquely determined by its values in any arbitrarily small disk $D (a,\rho )\subset D (a,r)$ (because the Taylor series coefficient $c_{n}= \frac{f^{(n)}(a)}{n!}$ for $n \in \mathbb{N}_{0}$).

This can be generalised to arbitrary domains.
\begin{theorem}[Unique continuation for analytic functions]
      Let $U,V$ be domains such that $U \subset V$. If $g_1 ,g_2 : V \rightarrow \mathbb{C}$ are analytic and $g_1 =g_2 $ on $U$, then $g_1 =g_2 $ on $V$.

      Equivalently, if $f: U \rightarrow \mathbb{C}$ is analytic, then there is at most one analytic function $g: V \rightarrow \mathbb{C}$ such that $g=f$ on $U$.
      \begin{notation}
           We call $g$ the \vocab{analytic continuation of $f$ to $V$}.
      \end{notation}
\end{theorem}
\begin{proof}
      Let $g_1 ,g_2 $ be analytic with $g_1 |_{U}=g_2 |_{U}$. Then $h=g_1 -g_2 $ is analytic and $h (z)=0$ on $U$. We want to show that $h\equiv 0$ on $V$.
\end{proof}
\end{document}